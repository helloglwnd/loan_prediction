{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import init_notebook_mode\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import ensemble, model_selection, metrics \n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split , cross_val_score , RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('/Users/olegmonahov/Downloads/test_lAUu6dG.csv')\n",
    "df_train=pd.read_csv('/Users/olegmonahov/Downloads/train_ctrUa4K.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exploratory Data analysis </b> <br>\n",
    "At this stage, I'm visualizing different features to understand what might be a driver of application approvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.kdeplot(df_train[df_train['Loan_Status']=='N']['ApplicantIncome'], ax=ax)\n",
    "sns.kdeplot(df_train[df_train['Loan_Status']=='Y']['ApplicantIncome'], ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df_train[df_train['Loan_Status']=='Y']['Married'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage I'm trying to check correlation of each feature with each other to understand what might be driving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correlation_heatmap(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue that a lot of data is Object formats and as the model can work wiht numerical data only, we need to translate it to int formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dealing with categorical data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to approach the problem of categorical data, we'll create a stand alone data frame to deal with objects\n",
    "obj_df = df_train.select_dtypes(include=['object']).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df['Self_Employed'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we need to decide how to deal with missing data. In this case, I'll be just replacing it with the most common values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. changing all the missing values of gender because self employed is the most common option \n",
    "\n",
    "obj_df = obj_df.fillna({\"Self_Employed\": \"No\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df = obj_df.fillna({\"Gender\": \"Male\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df['Dependents'].value_counts()\n",
    "obj_df = obj_df.fillna({\"Dependents\": \"0\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df['Married'].value_counts()\n",
    "obj_df = obj_df.fillna({\"Married\": \"0\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking shape of a new object dataframe\n",
    "obj_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I'm using .cat.codes to translate Object data to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df[\"Gender\"] = obj_df[\"Gender\"].astype('category')\n",
    "\n",
    "obj_df[\"Gender\"] = obj_df[\"Gender\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obj_df[\"Married\"] = obj_df[\"Married\"].astype('category')\n",
    "\n",
    "obj_df[\"Married\"] = obj_df[\"Married\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obj_df[\"Dependents\"] = obj_df[\"Dependents\"].astype('category')\n",
    "\n",
    "obj_df[\"Dependents\"] = obj_df[\"Dependents\"].cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obj_df[\"Education\"] = obj_df[\"Education\"].astype('category')\n",
    "\n",
    "obj_df[\"Education\"] = obj_df[\"Education\"].cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obj_df[\"Self_Employed\"] = obj_df[\"Self_Employed\"].astype('category')\n",
    "\n",
    "obj_df[\"Self_Employed\"] = obj_df[\"Self_Employed\"].cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obj_df[\"Property_Area\"] = obj_df[\"Property_Area\"].astype('category')\n",
    "\n",
    "obj_df[\"Property_Area\"] = obj_df[\"Property_Area\"].cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obj_df[\"Loan_Status\"] = obj_df[\"Loan_Status\"].astype('category')\n",
    "\n",
    "obj_df[\"Loan_Status\"] = obj_df[\"Loan_Status\"].cat.codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the resulting dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we achieved what was intended - getting all the categorical data as numerical values, dealing with NaNs succesfully "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cleaning numerical data </h3>\n",
    "At this stage we need to deal with missing values for numerical part of a dataset. For this let's build a stand alone DF with numerical data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_df = df_train.select_dtypes(include=['int','float64']).copy()\n",
    "int_df = int_df.fillna({\"LoanAmount\": np.mean(int_df['LoanAmount'])})\n",
    "int_df = int_df.fillna({\"Loan_Amount_Term\": np.mean(int_df['Loan_Amount_Term'])})\n",
    "int_df = int_df.fillna({\"Credit_History\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to concatenate both numerical and object part of data set to get the resulting dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([int_df, obj_df], axis=1, join='inner')\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correlation_heatmap(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with outliers? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be beneficial to get rid of outliers as they might be affecting results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=result[result['ApplicantIncome']<34000]\n",
    "result=result[result['CoapplicantIncome']<25300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dealing with multicollinearity</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calc_vif(X):\n",
    "\n",
    "    # Calculating VIF\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z=result[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term',\n",
    "        'Credit_History', 'Gender', 'Married',\n",
    "       'Dependents', 'Education', 'Self_Employed', 'Property_Area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(calc_vif(Z)['VIF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_vif(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_vif(result[['ApplicantIncome', 'CoapplicantIncome', 'Loan_Amount_Term',\n",
    "        'Credit_History', 'Gender', 'Married',\n",
    "       'Dependents', 'Education', 'Self_Employed', 'Property_Area']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=result.sort_values(by='Loan_ID')\n",
    "y = result['Loan_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x=result[['ApplicantIncome', 'CoapplicantIncome', 'Loan_Amount_Term',\n",
    "        'Credit_History', 'Gender', 'Married',\n",
    "       'Dependents', 'Education', 'Self_Employed', 'Property_Area']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Normalizing values in training set </h3>\n",
    "Obviously data is coming with in a very different numerical ranges. In the next step I'll be scaling those different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_x.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Random forest</h2>\n",
    "<br>\n",
    "I'll try to use Random forest as estimator for this excercise. I've approached to ML algo selection in a separate excercise and decided that RF is good enough. I'll spend more time on trying to understand what are the best parameters for selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = ensemble.RandomForestClassifier()\n",
    "rf=estimator.fit(x_scaled,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a task of selecting best possible parameters for the algorythm. I'll use the method RandomizedSearchCV for trying to find the best parameters out of those in range of rf_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param = {'n_estimators':list(range(5,270)) , \n",
    "         'min_samples_leaf':list(range(2,30)) , \n",
    "         'criterion':['gini','entropy'] ,\n",
    "         'max_depth':list(range(1,40)),\n",
    "            'min_samples_split':list(range(2,70))\n",
    "}\n",
    "rscv = RandomizedSearchCV(rf,\n",
    "                          param_distributions=rf_param , \n",
    "                          cv =10 , n_iter=10 , scoring = 'accuracy',n_jobs =-1 , verbose =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv.fit(x_scaled,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'm retrieving the best parameter configuration that RandomizedSearchCV gave us along with the best score. The idea is tbat by applying it to our estimator we'll get the best score at our training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rscv.best_score_)\n",
    "print(rscv.best_estimator_)\n",
    "print(rscv.best_index_)\n",
    "print(rscv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's apply those parameters and see what score it gives on CV sets. We'll be looking at the model with different number of trees by wrapping estimator in for loop with the tree range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = [1] + list(range(10, 65, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using CV with scoring aimed for accuracy. Let's store the score values in scoring list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scoring = []\n",
    "for n_tree in n_trees:\n",
    "    estimator = ensemble.RandomForestClassifier(n_estimators = n_tree, min_samples_split=15,\n",
    "                                                criterion='entropy',max_depth=5, min_samples_leaf=23, warm_start=False)\n",
    "    score = model_selection.cross_val_score(estimator, x_scaled, y, \n",
    "                                             scoring = 'accuracy', cv = 5)    \n",
    "    scoring.append(score)\n",
    "scoring = np.asmatrix(scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot and see how Accuracy changes with the number of leafs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.plot(n_trees, scoring.mean(axis = 1), marker='.')\n",
    "pylab.grid(True)\n",
    "pylab.xlabel('estimators')\n",
    "pylab.ylabel('score')\n",
    "pylab.title('Accuracy ')\n",
    "pylab.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>XGBClassifier </h3>\n",
    "<br>\n",
    "Though we decided to use Random Forest as classifier, let's try and see how XGBClassifier will work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator=xgb.XGBClassifier()\n",
    "xgb_est=estimator.fit(x_scaled,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting RandomizedSearchCV to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param = {\n",
    "        'min_child_weight': [1, 3, 21],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'colsample_bytree': [0.3, 0.8, 1.0],\n",
    "        'learning_rate':[0.001, 0.1, 0.005],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(xgb_est ,param_distributions=xgb_param ,  cv =5 , n_iter=10 , scoring = 'accuracy',n_jobs =-1 , verbose =10)\n",
    "rscv.fit(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rscv.best_score_)\n",
    "print(rscv.best_estimator_)\n",
    "print(rscv.best_index_)\n",
    "print(rscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = xgb.XGBClassifier(n_estimators=5, min_child_weight =3, max_depth=3, learning_rate=0.001,colsample_bytree=1.0)\n",
    "score = model_selection.cross_val_score(estimator, x_scaled, y, \n",
    "                                             scoring = 'accuracy', cv = 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_scoring = []\n",
    "for n_tree in n_trees:\n",
    "    estimator = xgb.XGBClassifier(learning_rate=0.9, max_depth=10, booster='dart', n_estimators=n_tree, min_child_weight=5)\n",
    "    score = model_selection.cross_val_score(estimator, x_scaled, y, \n",
    "                                             scoring = 'accuracy', cv = 10)    \n",
    "    xgb_scoring.append(score)\n",
    "xgb_scoring = np.asmatrix(xgb_scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.plot(n_trees, scoring.mean(axis = 1), marker='.', label='RandomForest')\n",
    "pylab.plot(n_trees, xgb_scoring.mean(axis = 1), marker='.', label='XGBoost')\n",
    "pylab.grid(True)\n",
    "pylab.xlabel('n_trees')\n",
    "pylab.ylabel('score')\n",
    "pylab.title('Accuracy score')\n",
    "pylab.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ESTIMATOR IS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_final=ensemble.RandomForestClassifier(n_estimators = 40, min_samples_split=15,\n",
    "                                                criterion='entropy',max_depth=5, min_samples_leaf=23, warm_start=False)\n",
    "estimator_final.fit(x_scaled,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Transforming test data set </h2>\n",
    "We'll need to do the same manipulations (fitting category data, dealing with missing values) for test data set as we did for train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df_test = df_test.select_dtypes(include=['object']).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df_test = obj_df_test.fillna({\"Self_Employed\": \"No\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df_test['Gender'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df_test['Gender'].value_counts()\n",
    "obj_df_test = obj_df_test.fillna({\"Gender\": \"Male\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df_test['Dependents'].value_counts()\n",
    "obj_df_test = obj_df_test.fillna({\"Dependents\": \"0\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df_test['Self_Employed'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df_test = obj_df_test.fillna({\"Self_Employed\": \"No\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obj_df_test[obj_df_test.isnull().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obj_df_test[\"Gender\"] = obj_df_test[\"Gender\"].astype('category')\n",
    "\n",
    "obj_df_test[\"Gender\"] = obj_df_test[\"Gender\"].cat.codes\n",
    "obj_df_test[\"Married\"] = obj_df_test[\"Married\"].astype('category')\n",
    "\n",
    "obj_df_test[\"Married\"] = obj_df_test[\"Married\"].cat.codes\n",
    "obj_df_test[\"Dependents\"] = obj_df_test[\"Dependents\"].astype('category')\n",
    "\n",
    "obj_df_test[\"Dependents\"] = obj_df_test[\"Dependents\"].cat.codes\n",
    "obj_df_test[\"Education\"] = obj_df_test[\"Education\"].astype('category')\n",
    "\n",
    "obj_df_test[\"Education\"] = obj_df_test[\"Education\"].cat.codes\n",
    "obj_df_test[\"Self_Employed\"] = obj_df_test[\"Self_Employed\"].astype('category')\n",
    "\n",
    "obj_df_test[\"Self_Employed\"] = obj_df_test[\"Self_Employed\"].cat.codes\n",
    "obj_df_test[\"Property_Area\"] = obj_df_test[\"Property_Area\"].astype('category')\n",
    "\n",
    "obj_df_test[\"Property_Area\"] = obj_df_test[\"Property_Area\"].cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_df_test = df_test.select_dtypes(include=['int','float64']).copy()\n",
    "\n",
    "\n",
    "int_df_test = int_df_test.fillna({\"LoanAmount\": np.mean(int_df_test['LoanAmount'])})\n",
    "\n",
    "int_df_test = int_df_test.fillna({\"Loan_Amount_Term\": np.mean(int_df_test['Loan_Amount_Term'])})\n",
    "\n",
    "int_df_test = int_df_test.fillna({\"Credit_History\": 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_df_test[int_df.isnull().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = pd.concat([int_df_test, obj_df_test], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test[result_test.isnull().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=result_test[['ApplicantIncome', 'CoapplicantIncome', 'Loan_Amount_Term',\n",
    "        'Credit_History', 'Gender', 'Married',\n",
    "       'Dependents', 'Education', 'Self_Employed', 'Property_Area']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_predict=estimator_final.predict(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df=pd.DataFrame(y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing resulting data frame for the output acceptable by competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=pd.concat([df_test['Loan_ID'], predict_df], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.columns=['Loan_ID','Loan_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.columns=['Loan_ID','Loan_Status']\n",
    "res['new_statys']=res['Loan_Status'].replace({1: \"Y\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.columns=['Loan_ID','Loan_Status','new_statys']\n",
    "# res['new_statys']=res['Loan_Status'].replace({0: \"N\"})\n",
    "res['new_statys']=res['Loan_Status'].replace({0: \"N\", 1: \"Y\"})\n",
    "res=res[['Loan_ID','new_statys']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.columns=['Loan_ID','Loan_Status']\n",
    "res['new_statys']=res['Loan_Status'].replace({1: \"Y\"})\n",
    "res['new_statys']=res['Loan_Status'].replace({0: \"N\", 1: \"Y\"})\n",
    "res=res[['Loan_ID','new_statys']]\n",
    "res.columns=['Loan_ID','Loan_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('submission_for_loan_competition_xgb12.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
